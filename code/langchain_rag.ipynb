{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5630b0ca",
   "metadata": {
    "id": "5630b0ca"
   },
   "source": [
    "# Build a Retrieval Augmented Generation (RAG) App: Part 1\n",
    "- 출처 : https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/tutorials/rag.ipynb\n",
    "- 수정사항 : 설명 한글화 및 간소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1918ba2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1918ba2f",
    "outputId": "251f2d7a-872b-47af-b1e0-3233a56b4238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain langchain_openai langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ZNk_egt8PZK4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNk_egt8PZK4",
    "outputId": "23e73d82-0779-4909-e17b-5c063cf1b890"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26ef9d35",
   "metadata": {
    "id": "26ef9d35"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a199c764-5dfd-45cf-a4d4-731f2c3d474f",
   "metadata": {
    "id": "a199c764-5dfd-45cf-a4d4-731f2c3d474f"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4db6b46-ea3f-4994-9d54-d7c84beb50cc",
   "metadata": {
    "id": "f4db6b46-ea3f-4994-9d54-d7c84beb50cc"
   },
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2d316-922c-4318-b72d-486fd6813b94",
   "metadata": {
    "id": "93b2d316-922c-4318-b72d-486fd6813b94"
   },
   "source": [
    "## Preview\n",
    "\n",
    "이 가이드에서는 웹사이트 콘텐츠에 대한 질문에 답하는 앱을 빌드합니다.   \n",
    "사용할 특정 웹사이트는 Lilian Weng의  [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)  블로그 게시물로,  \n",
    " 게시물 콘텐츠에 대한 질문을 할 수 있습니다.\n",
    "\n",
    "약 50줄의 코드로 이를 수행하기 위한 간단한 인덱싱 파이프라인과 RAG 체인을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9ea6a-f914-4f50-8e35-52e6c34b8001",
   "metadata": {
    "id": "efa9ea6a-f914-4f50-8e35-52e6c34b8001"
   },
   "source": [
    "## 1. Indexing\n",
    "\n",
    "### Loading documents\n",
    "\n",
    "DocumentLoader로 블로그 게시물 콘텐츠를 로드 합니다.   \n",
    "이는 소스에서 데이터를 로드하고\n",
    "[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)\n",
    "객체 목록을 반환하는 객체입니다.\n",
    "\n",
    "[WebBaseLoader](/docs/integrations/document_loaders/web_base)를 사용하겠습니다.   \n",
    "\n",
    "`urllib`를 사용하여 웹 URL에서 HTML을 로드하고 `BeautifulSoup`를 사용하여 텍스트로 구문 분석합니다.    \n",
    "`bs_kwargs`를 통해 `BeautifulSoup` 파서에 매개변수를 전달하여 HTML -\\> 텍스트 파싱을 사용자 정의할 수 있습니다([BeautifulSoup\n",
    "docs](https://beautiful-soup-4.readthedocs.io/en/latest/#beautifulsoup) 참조).  \n",
    "이 경우 클래스 \"post-content\", \"post-title\" 또는\n",
    "\"post-header\"가 있는 HTML 태그만 관련이 있으므로 다른 모든 태그를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0971b5-8579-4a89-bd2e-9029dda4c4f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b0971b5-8579-4a89-bd2e-9029dda4c4f1",
    "outputId": "473811e2-09b5-4d82-800b-4655deecc524"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a560025-fb86-4b7e-9586-da263bbad481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a560025-fb86-4b7e-9586-da263bbad481",
    "outputId": "8c1eadd9-c7d3-4469-ec55-833ce141c97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd",
   "metadata": {
    "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd"
   },
   "source": [
    "#### 더 자세히 알아보기\n",
    "\n",
    "`DocumentLoader`: 소스에서 데이터를 `Documents` list 로드하는 객체 .\n",
    "\n",
    "### Splitting documents\n",
    "로드된 문서는 42,000자를 넘으며 많은 모델의 컨텍스트 창에 맞추기에는 너무 깁니다.    \n",
    "컨텍스트 창에 전체 게시물을 맞출 수 있는 모델의 경우에도 모델은 매우 긴 입력에서 정보를 찾는 데 어려움을 겪을 수 있습니다.  \n",
    "이를 처리하기 위해 문서를 임베딩 및 벡터 저장을 위한 청크로 분할합니다.   \n",
    "이렇게 하면 런타임에 블로그 게시물에서 가장 관련성 있는 부분만 검색하는 데 도움이 됩니다.\n",
    "\n",
    "RecursiveCharacterTextSplitte는 각 청크가 적절한 크기가 될 때까지 줄바꿈과 같은 일반적인 구분 기호를 사용하여 문서를 재귀적으로 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753e1484-e21b-4f62-9866-b3a5971f88a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753e1484-e21b-4f62-9866-b3a5971f88a7",
    "outputId": "e6acdabd-a37b-453f-d73a-83a7b0f950d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6",
   "metadata": {
    "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6"
   },
   "source": [
    "#### 더 자세히 알아보기\n",
    "\n",
    "`TextSplitter`: `Document` list를 더 작은 청크로 분할하는 객체입니다.   `DocumentTransformer`의 하위 클래스입니다.  \n",
    "`DocumentTransformer`: Document 객체 목록에서 변환을 수행하는 객체.\n",
    "\n",
    "\n",
    "### Storing documents\n",
    "텍스트 청크를 인덱싱하여 런타임에 검색할 수 있도록 합니다.   \n",
    "각 문서 분할의 내용을 임베드하고 이러한 임베딩을 벡터 저장소에 저장합니다.  \n",
    "입력 쿼리가 주어지면 벡터 검색을 사용하여 관련 문서를 검색할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d455e1-c681-4665-9470-58dbeca050d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00d455e1-c681-4665-9470-58dbeca050d4",
    "outputId": "1f5eff13-b418-48ae-e118-66e126820aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['74f6149a-8211-4ee1-beaa-14d9eaea8f31', 'bdc520bb-c9c8-4182-b41c-98deea05e31c', 'fdcd673a-2966-4bed-80e5-06b4b20d1b10']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57666234-a5b3-4abc-b079-755241bb2b98",
   "metadata": {
    "id": "57666234-a5b3-4abc-b079-755241bb2b98"
   },
   "source": [
    "#### 더 자세히 알아보기\n",
    "\n",
    "`Embeddings`: 텍스트 임베딩 모델을 감싸는 래퍼로, 텍스트를 임베딩으로 변환하는 데 사용됩니다.\n",
    "\n",
    "`VectorStore`: 벡터 데이터베이스를 감싸는 래퍼로, 임베딩을 저장하고\n",
    "쿼리하는 데 사용됩니다.\n",
    "\n",
    "\n",
    "파이프라인의 **인덱싱** 부분이 완료되었습니다. 이 시점에서\n",
    "블로그 게시물의 청크된 콘텐츠를 포함하는 쿼리 가능한 벡터 저장소가 있습니다.\n",
    "사용자 질문이 주어지면 이상적으로는\n",
    "질문에 답하는 블로그 게시물의 스니펫을 반환할 수 있어야 합니다.\n",
    "\n",
    "## 2. Retrieval and Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46f378c5-858c-488f-8aef-8b59a6280791",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46f378c5-858c-488f-8aef-8b59a6280791",
    "outputId": "9d023b76-6745-4505-fd47-c56c1eceaabb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfe84d-cc19-4227-bee4-56b69508ab11",
   "metadata": {
    "id": "77dfe84d-cc19-4227-bee4-56b69508ab11"
   },
   "source": [
    "[LangGraph](https://langchain-ai.github.io/langgraph/)를 사용하여 검색 및 생성 단계를 단일 애플리케이션으로 연결합니다. 이렇게 하면 여러 가지 이점이 있습니다.\n",
    "\n",
    "- 애플리케이션 로직을 한 번 정의하면 스트리밍, 비동기 및 일괄 호출을 포함한 여러 호출 모드를 자동으로 지원할 수 있습니다.\n",
    "- [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)을 통해 간소화된 배포를 얻습니다.\n",
    "- LangSmith가 애플리케이션의 단계를 자동으로 추적합니다.\n",
    "- 최소한의 코드 변경으로 [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) 및 [human-in-the-loop approval](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)을 포함한 주요 기능을 애플리케이션에 쉽게 추가할 수 있습니다.\n",
    "\n",
    "LangGraph를 사용하려면 세 가지를 정의해야 합니다.\n",
    "\n",
    "1. 애플리케이션의 상태;\n",
    "2. 애플리케이션의 노드(i.e., application steps);\n",
    "3. 애플리케이션의 \"제어 흐름\"(e.g., the ordering of the steps).\n",
    "\n",
    "#### State:\n",
    "\n",
    "애플리케이션의 [state](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)는 애플리케이션에 입력되는 데이터, 단계 간에 전송되는 데이터, 애플리케이션에서 출력되는 데이터를 제어합니다.   \n",
    "일반적으로 `TypedDict`이지만 [Pydantic BaseModel](https://langchain-ai.github.io/langgraph/how-tos/state-model/)일 수도 있습니다.\n",
    "\n",
    "간단한 RAG 애플리케이션의 경우 입력 질문, 검색된 컨텍스트, 생성된 답변을 추적할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bdc7c33-67f4-40c3-a0f5-9b846bc6e35c",
   "metadata": {
    "id": "3bdc7c33-67f4-40c3-a0f5-9b846bc6e35c"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77868d9a-892f-4b2c-b706-850f96b4464f",
   "metadata": {
    "id": "77868d9a-892f-4b2c-b706-850f96b4464f"
   },
   "source": [
    "#### Nodes (application steps)\n",
    "\n",
    "두 단계로 이루어진 간단한 순서로 시작해 보겠습니다. : retrieval and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdabbf44-cbee-46a4-98e4-794fdfc8bb3b",
   "metadata": {
    "id": "bdabbf44-cbee-46a4-98e4-794fdfc8bb3b"
   },
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17",
   "metadata": {
    "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17"
   },
   "source": [
    "검색 단계(retrieval step)는 입력 질문을 사용하여 유사성 검색을 실행하고, 생성 단계는 검색된 컨텍스트와 원래 질문을 채팅 모델의 프롬프트로 포맷합니다.\n",
    "\n",
    "#### 제어 흐름\n",
    "\n",
    "마지막으로, 애플리케이션을 단일 그래프 객체로 컴파일합니다. 이 경우 검색 및 생성 단계를 단일 시퀀스로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "418ddefb-9a1d-42bf-9d23-e525268312a4",
   "metadata": {
    "id": "418ddefb-9a1d-42bf-9d23-e525268312a4"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b127f4-8411-4214-8cdd-a281771ab708",
   "metadata": {
    "id": "20b127f4-8411-4214-8cdd-a281771ab708"
   },
   "source": [
    "LangGraph에는 애플리케이션의 제어 흐름을 시각화하기 위한 기본 제공 유틸리티도 함께 제공됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feabc04f-b509-4452-8e2b-d7c7b7585a18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "feabc04f-b509-4452-8e2b-d7c7b7585a18",
    "outputId": "a846632a-3767-407d-bad6-441b4099ecec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7dc4d-cac8-4be9-b44c-df097dc28c81",
   "metadata": {
    "id": "31f7dc4d-cac8-4be9-b44c-df097dc28c81"
   },
   "source": [
    "<details>\n",
    "<summary>LangGraph를 사용해야 합니까?</summary>\n",
    "\n",
    "LangGraph는 RAG 애플리케이션을 빌드하는 데 필요하지 않습니다. 실제로 개별 구성 요소를 호출하여 동일한 애플리케이션 로직을 구현할 수 있습니다.:\n",
    "\n",
    "```python\n",
    "question = \"...\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "prompt = prompt.invoke({\"question\": question, \"context\": docs_content})\n",
    "answer = llm.invoke(prompt)\n",
    "```\n",
    "\n",
    "LangGraph의 이점은 다음과 같습니다.\n",
    "\n",
    "- 다중 호출 모드 지원: 출력 토큰을 스트리밍하거나 개별 단계의 결과를 스트리밍하려는 경우 이 논리를 다시 작성해야 합니다.\n",
    "- [LangSmith](https://docs.smith.langchain.com/)를 통한 추적 및 [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)을 통한 배포에 대한 자동 지원\n",
    "- 지속성, 인간 참여 및 기타 기능 지원.\n",
    "\n",
    "많은 사용 사례에서 대화형 경험에서 RAG가 필요하므로 사용자는 상태 기반 대화를 통해 상황에 맞는 답변을 받을 수 있습니다. LangGraph의 상태 관리 및 지속성은 이러한 애플리케이션을 엄청나게 단순화합니다\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9c057-5a08-46a3-8c7d-6a314d1e777d",
   "metadata": {
    "id": "eee9c057-5a08-46a3-8c7d-6a314d1e777d"
   },
   "source": [
    "#### 사용법\n",
    "\n",
    "애플리케이션을 테스트해 봅시다! LangGraph는 동기, 비동기, 스트리밍을 포함한 여러 호출 모드를 지원합니다.\n",
    "\n",
    "Invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b93ba-f0a7-44c4-a894-fe895bd5b009",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "663b93ba-f0a7-44c4-a894-fe895bd5b009",
    "outputId": "da5fb1fb-d8c1-403b-a589-aefdcf4210cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='e90bffdc-ea53-44f6-bd79-334051db16b8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='fdcd673a-2966-4bed-80e5-06b4b20d1b10', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='0039befa-153c-4f31-97bd-ca31e6fd4141', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35126}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease'), Document(id='72c40499-1bc2-4d63-a8f2-8e854a8942ef', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35126}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]\n",
      "\n",
      "\n",
      "Answer: Task Decomposition은 복잡한 업무를 여러 개의 작은 단계로 나누는 과정을 의미합니다. 이를 통해 모델이 \"단계별로 생각하라\"는 지시를 받고, 어려운 작업을 더 간단하고 관리하기 쉬운 작업으로 쪼개어 효율적으로 수행할 수 있도록 합니다. 이 방법은 모델의 사고 과정을 해석하는 데에도 도움이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"Task Decomposition 이 뭐야? 한글로 설명해줘\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef88f30-40ca-476b-808d-794cb72d401f",
   "metadata": {
    "id": "4ef88f30-40ca-476b-808d-794cb72d401f"
   },
   "source": [
    "Stream 스텝:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6314a96-aab8-4ecc-bbf9-094fa2aa0e50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6314a96-aab8-4ecc-bbf9-094fa2aa0e50",
    "outputId": "d189fd0c-2754-4aeb-8984-282adb1d99eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='e90bffdc-ea53-44f6-bd79-334051db16b8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='fdcd673a-2966-4bed-80e5-06b4b20d1b10', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='0bc0f695-d15a-43c6-92b5-444fbd34ac47', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='c0870088-97fc-4b2a-a687-d67a61cc148e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task Decomposition은 복잡한 과제를 더 작고 간단한 단계로 나누는 과정입니다. 이를 통해 모델은 \"단계별로 생각하라\"는 방식으로 문제를 해결할 수 있도록 도와주며, 각 단계에서 다수의 사고 가능성을 탐색할 수도 있습니다. 이 과정은 복잡한 작업을 관리하기 쉽게 만들어줍니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"Task Decomposition 이 뭐야? 한글로 설명해줘\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860142d-d50b-4526-a03f-a59a763117fe",
   "metadata": {
    "id": "f860142d-d50b-4526-a03f-a59a763117fe"
   },
   "source": [
    "토큰 스트리밍:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28625cc3-0f77-4143-af51-ce0fd6682120",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28625cc3-0f77-4143-af51-ce0fd6682120",
    "outputId": "5c04696e-307b-4038-8625-c4b513783028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| De|composition|은| 복|잡|한| 작업|을| 더| 작|고| 단|순|한| 단계|로| 나|누|는| 과정|입니다|.| 이를| 통해| 각| 단계|에서| \"|사|고|하며|\"| 작업|을| 수행|할| 수| 있도록| 모델|에게| 지|침|을| 주|는| 방법|입니다|.| 예|를| 들어|,| 특정| 목표|를| 달|성|하기| 위한| 하|위| 목표|를| 정의|하거나| 작업|을| 수행|하는| 단계|들을| 나|열|하는| 것이| 포함|됩니다|.||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"Task Decomposition 이 뭐야? 한글로 설명해줘\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "956e7e78-c26c-4d2d-bf2e-4fc41ff40d37",
   "metadata": {
    "id": "956e7e78-c26c-4d2d-bf2e-4fc41ff40d37"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"다음 맥락을 사용하여 마지막 질문에 답하세요.\n",
    "답을 모른다면 모른다고만 말하고, 답을 만들어내려고 하지 마세요.\n",
    "최대 3문장을 사용하고 가능한 한 간결하게 답하세요.\n",
    "답변 끝에는 항상 \"질문해 주셔서 감사합니다!\"라고 말하세요.\n",
    "\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "도움이 되는 답변:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df00956a-6565-4c05-b201-32854dd2a889",
   "metadata": {
    "id": "df00956a-6565-4c05-b201-32854dd2a889",
    "outputId": "43523cfd-2d5b-41a9-b987-7f7efd893dbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114878bd-a334-41ed-8013-ec4ce0a9112b",
   "metadata": {
    "id": "114878bd-a334-41ed-8013-ec4ce0a9112b"
   },
   "source": [
    "벡터 스토어의 문서를 업데이트해야 합니다.   \n",
    "이를 위해 간단한 [InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html)를 사용합니다.   \n",
    "특정 기능 중 일부(예: 메타데이터 필터링)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebb3cbd7-7c75-4cc0-a198-ff7c54a0c43a",
   "metadata": {
    "id": "ebb3cbd7-7c75-4cc0-a198-ff7c54a0c43a"
   },
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08aaccd-b3df-45e9-8646-d6ea20215e62",
   "metadata": {
    "id": "c08aaccd-b3df-45e9-8646-d6ea20215e62"
   },
   "source": [
    "다음으로 검색 쿼리에 대한 스키마를 정의해 보겠습니다.  \n",
    "이 목적을 위해 구조화된 출력을 사용합니다.  \n",
    "여기서는 문자열 쿼리와 문서 섹션(\"beginning\", \"middle\", \"end\")을 포함하는 쿼리를 정의하지만, 원하는 대로 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87f9c8c3-3e99-426d-aa65-fec4b9155c3f",
   "metadata": {
    "id": "87f9c8c3-3e99-426d-aa65-fec4b9155c3f"
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399a870-cb06-4219-9b4f-cfa37cb8ab0f",
   "metadata": {
    "id": "6399a870-cb06-4219-9b4f-cfa37cb8ab0f"
   },
   "source": [
    "마지막으로, 사용자의 원시 입력에서 쿼리를 생성하는 단계를 LangGraph 애플리케이션에 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e8fcdcb-a4ff-41c3-97c7-92d81ab29f38",
   "metadata": {
    "id": "7e8fcdcb-a4ff-41c3-97c7-92d81ab29f38"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    # highlight-next-line\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# highlight-next-line\n",
    "def analyze_query(state: State):\n",
    "    # highlight-next-line\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    # highlight-next-line\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    # highlight-next-line\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    # highlight-start\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    # highlight-end\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# highlight-start\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "# highlight-end\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a62d34",
   "metadata": {
    "id": "28a62d34"
   },
   "source": [
    "<details>\n",
    "<summary>Full Code:</summary>\n",
    "\n",
    "```python\n",
    "from typing import Literal\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Update metadata (illustration purposes)\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "# Index chunks\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "\n",
    "# Define schema for search\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a92d539-f85d-434b-b911-51a1cf9b81da",
   "metadata": {
    "id": "8a92d539-f85d-434b-b911-51a1cf9b81da",
    "outputId": "c0221d86-aaf8-4f3b-fdfe-8431bd3a4b92"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cf8dc-a201-43ea-9965-02fcfd2fc316",
   "metadata": {
    "id": "653cf8dc-a201-43ea-9965-02fcfd2fc316"
   },
   "source": [
    "우리는 게시물 끝에서 맥락을 구체적으로 요청하여 구현을 테스트할 수 있습니다. 모델이 답변에 다른 정보를 포함한다는 점에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b420650-2d9e-4f5e-a8d8-ec36ae07423c",
   "metadata": {
    "id": "8b420650-2d9e-4f5e-a8d8-ec36ae07423c",
    "outputId": "b83d799d-9be6-4e60-b2cc-227bf3efff26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='2a562c90-8b8d-4de0-ba8d-094f2bc94212', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='0f9b13d3-25a6-4188-9b44-fef411214ee6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39085, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(id='78cfde08-913a-429c-b6fc-e37b1eae3028', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32941, 'section': 'end'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(id='da23bf42-be55-40ca-b48e-ca5fd18e04da', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35126, 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '게시물의 끝 부분에서는 Task Decomposition이 장기 계획과 과제 분해에서 여러 도전과제를 가지고 있다고 언급합니다. 특히 LLMs는 예상치 못한 오류에 직면했을 때 계획을 조정하는 데 어려움을 겪어 인간보다 덜 강인하다는 점이 강조됩니다. 이는 Trial and Error학습에서 오는 유연성을 결여한 결과입니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"게시물의 끝 부분에서는 Task Decomposition에 대해 무엇이라고 말합니까?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875a48a-c849-4da9-99e0-558b04884fb0",
   "metadata": {
    "id": "5875a48a-c849-4da9-99e0-558b04884fb0"
   },
   "source": [
    "스트리밍 단계와 [LangSmith 추적](https://smith.langchain.com/) 모두에서 이제 검색 단계에 입력된 구조화된 쿼리를 관찰할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "e6f11795-e19f-4697-bc6e-6d477355a1cd",
    "406534d4-66a3-4c27-b277-2bd2f5930cf5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
